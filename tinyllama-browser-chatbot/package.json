{
  "name": "tinyllama-browser-chatbot",
  "version": "1.0.0",
  "description": "An offline browser-based chatbot powered by TinyLlama 1.1B using WebLLM and WebGPU",
  "main": "index.html",
  "type": "module",
  "scripts": {
    "start": "python -m http.server 8000",
    "start-node": "npx http-server -p 8000 -c-1",
    "dev": "python -m http.server 8000",
    "serve": "npx http-server -p 8000 -c-1 --cors"
  },
  "keywords": [
    "ai",
    "chatbot",
    "tinyllama",
    "webllm",
    "webgpu",
    "offline",
    "browser",
    "llm",
    "machine-learning"
  ],
  "author": "AI Assistant",
  "license": "MIT",
  "dependencies": {
    "@mlc-ai/web-llm": "^0.2.46"
  },
  "devDependencies": {
    "http-server": "^14.1.1"
  },
  "engines": {
    "node": ">=14.0.0"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/your-username/tinyllama-browser-chatbot.git"
  },
  "bugs": {
    "url": "https://github.com/your-username/tinyllama-browser-chatbot/issues"
  },
  "homepage": "https://github.com/your-username/tinyllama-browser-chatbot#readme"
} 